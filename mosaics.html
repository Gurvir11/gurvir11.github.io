<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Mosaics - Gurvir Kooner</title>
    <link rel="stylesheet" href="style.css">
    <link rel="stylesheet" href="mediaqueries.css">
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
    <nav id="desktop-nav">
        <div class="logo">Gurvir Kooner</div>
        <div>
            <ul class="nav-links">
                <li><a href="index.html">Home</a></li>
                <li><a href="index.html#about">About</a></li>
                <li><a href="index.html#experience">Experience</a></li>
                <li><a href="index.html#projects">Projects</a></li>
                <li><a href="index.html#contact">Contact</a></li>
            </ul>
        </div>
    </nav>
    <nav id="hamburger-nav">
        <div class="logo">Gurvir Kooner</div>
        <div class="hamburger-menu">
            <div class="hamburger-icon" onclick="toggleMenu()">
                <span></span>
                <span></span>
                <span></span>
            </div>
            <div class="menu-links">
                <li><a href="index.html" onclick="toggleMenu()">Home</a></li>
                <li><a href="index.html#about" onclick="toggleMenu()">About</a></li>
                <li><a href="index.html#experience" onclick="toggleMenu()">Experience</a></li>
                <li><a href="index.html#projects" onclick="toggleMenu()">Projects</a></li>
                <li><a href="index.html#contact" onclick="toggleMenu()">Contact</a></li>
            </div>
        </div>
    </nav>
    
    <section id="project-header">
        <div class="banner-container">
            <img src="./assets/proj4.jpg" alt="Face Morphing" class="banner-img">
            <div class="banner-overlay">
                <h1 class="proj-title">Photo Mosaics</h1>
            </div>
        </div>
    </section>

    <section id="project-intro">
        <div class="section-container">
            <h2>Part A: Image Warping and Mosaicing</h1>
            <h2>Shooting the Pictures</h2>
            <p>
                Below are images I shot so the transforms between them are projective so I can create image mosaics using them.
                I chose images at School of Law, Haas, and South Hall.
            </p>
            <div class="before-after-container">
                <figure class="image-container">
                    <img src="assets/law-left.jpg" alt="Before Image" class="before-after-img">
                    <figcaption class="image-caption">
                        <strong>School of Law - Left</strong>
                    </figcaption>
                </figure>
                <figure class="image-container">
                    <img src="assets/law-right.jpg" alt="After Image" class="before-after-img">
                    <figcaption class="image-caption">
                        <strong>School of Law - Right</strong>
                    </figcaption>
                </figure>
            </div> 
            <div class="before-after-container">
                <figure class="image-container">
                    <img src="assets/haas-left.jpg" alt="Before Image" class="before-after-img">
                    <figcaption class="image-caption">
                        <strong>Haas - Left</strong>
                    </figcaption>
                </figure>
                <figure class="image-container">
                    <img src="assets/haas-right.jpg" alt="After Image" class="before-after-img">
                    <figcaption class="image-caption">
                        <strong>Haas - Right</strong>
                    </figcaption>
                </figure>
            </div> 
            <div class="before-after-container">
                <figure class="image-container">
                    <img src="assets/south-left.jpg" alt="Before Image" class="before-after-img">
                    <figcaption class="image-caption">
                        <strong>South Hall - Left</strong>
                    </figcaption>
                </figure>
                <figure class="image-container">
                    <img src="assets/south-right.jpg" alt="After Image" class="before-after-img">
                    <figcaption class="image-caption">
                        <strong>South Hall - Right</strong>
                    </figcaption>
                </figure>
            </div> 
            <h2>Recovering Homographies</h2>
            <p>
                We can represent the projective transformation between each left and right image using a homography matrix, \(H\),
                Our projective transformation can be written as \(Hp = p'\). Where \(p\) is a homogeneous coordinate of a point in the left image,
                and \(p'\) is its corresponding point in the right image. 

                $$
                    H = 
                    \begin{bmatrix}
                    a & b & c \\
                    d & e & f \\
                    g & h & 1
                    \end{bmatrix}
                $$
                
                The projective transformation is as follows: 
                $$
                    \begin{bmatrix}
                    a & b & c \\
                    d & e & f \\
                    g & h & 1
                    \end{bmatrix}
                    \begin{bmatrix}
                    x_1 \\
                    y_1 \\
                    1
                    \end{bmatrix}
                    =
                    \begin{bmatrix}
                    wx_1' \\
                    wy_1' \\
                    w
                    \end{bmatrix}
                $$

                Using our corresponding pairs of points we can recover the homography, \(H\), by solving the following system using least squares.
                We stack each correspondence pair in a matrix, \(P\), on the left, and a vector \(q\) on the right. Since we have 8 degrees of freedom,
                we need at least 4 points.

                $$
                \begin{bmatrix}
                x_1 & y_1 & 1 & 0 & 0 & 0 & -x_1'x_1 & -x_1'y_1 \\
                0 & 0 & 0 & x_1 & y_1 & 1 & -y_1'x_1 & -y_1'y_1 \\
                \end{bmatrix}
                \begin{bmatrix}
                a \\
                b \\
                c \\
                d \\
                e \\
                f \\
                g \\
                h
                \end{bmatrix}
                =
                \begin{bmatrix}
                x_1' \\
                y_1'
                \end{bmatrix}
                $$

            </p>
            <h2>Warp the Images</h2>
            <p>
                After we recovered the homography, \(H\), we want to be able to warp images using it. To do this we take the corners
                of the image we would like to warp and apply H to get the tranformed coordinates on the warped image.

                We do this as follows:
                $$
                \begin{bmatrix}
                a & b & c \\
                d & e & f \\
                g & h & 1
                \end{bmatrix}
                \begin{bmatrix}
                x_1 \\
                y_1 \\
                1
                \end{bmatrix}
                =
                \begin{bmatrix}
                wx_1' \\
                wy_1' \\
                w
                \end{bmatrix}
                $$
                $$
                warped\ pixel\ location =                 
                \begin{bmatrix}
                \frac{x_1'}{w} \\
                \frac{y_1'}{w} 
                \end{bmatrix}
                $$

                Afterwards, we create a bounding box in the warped image that contains these morphed corners. We use inverse warping to
                determine what these pixels would be in the original images and use interpolation to set these pixels in our warped image.
            </p>
            <h2>Image Rectification</h2>
            <p>
                To test if our warp works lets try to "rectify" some images by selecting a planar surface of an image and projecting it onto
                a flat frontal-facing plane.

                Here are the results below:
            </p>
            <div class="before-after-container">
                <figure class="image-container">
                    <h5>Physics Building: Original</h5>
                    <img src="assets/physics-original.png" alt="Before Image" class="before-after-img">
                </figure>
                <figure class="image-container">
                    <h5>Physics Building: Warped</h5>
                    <img src="assets/physics-warped.png" alt="After Image" class="before-after-img">
                </figure>
            </div>
            <div class="before-after-container">
                <figure class="image-container">
                    <h5>Hearst Mining: Original</h5>
                    <img src="assets/hearst-original.png" alt="Before Image" class="before-after-img">
                </figure>
                <figure class="image-container">
                    <h5>Hearst Mining: Warped</h4>
                    <img src="assets/hearst-warped.png" alt="After Image" class="before-after-img">
                </figure>
            </div>   
            <p>
                We see the surfaces we chose have been warped to be frontal-facing.
            </p>
            <h2>Image Mosaics</h2>
            <p>
                After we project the left image into the right images space, we need to blend the two images together.
                We can do this using 2-band "laplacian stack" blending. First, we create a mask of where the projected images
                are on our blending canvas that will encompass both images. After we create these masks, we apply a distance transform
                to find the distances of pixels in the mask to their nearest edge and then normalize these distance values from 0 to 1
                for both images.
            </p>
            <p>Here are the results of this step on the School of Law left and right images: </p>
            <div class="before-after-container">
                <figure class="image-container">
                    <img src="assets/law-left-d1.jpg" alt="Before Image" class="before-after-img">
                    <figcaption class="image-caption">
                        <strong>School of Law: Left Distance Transform</strong>
                    </figcaption>
                </figure>
                <figure class="image-container">
                    <img src="assets/law-right-d2.jpg" alt="After Image" class="before-after-img">
                    <figcaption class="image-caption">
                        <strong>School of Law: Right Distance Transform</strong>
                    </figcaption>
                </figure>
            </div>
            <p>
                Now we apply a low-pass filter and a high-pass filter on the left and right images. We blend the low-pass
                and high-pass left and right images separately and sum them to create our blended images.
                To blend the low-pass filtered images we apply a weighted linear combination on the left and right images using the distance
                transformed computed above.

                To blend the high-pass filtered images we just selected the pixel from the image that has a greater distance value in each image.

            </p>
            <p>
                Here are the results of the mosaics using the images chosen from the Shooting the Pictures section:
            </p>
            <figure class="centered-image">
                <img src="./assets/law-mosaic.jpg" alt="Derek Hybrid Image">
                <figcaption><strong>School of Law Mosaic</strong></figcaption>
            </figure>
            <figure class="centered-image">
                <img src="./assets/haas-mosaic.jpg" alt="Derek Hybrid Image">
                <figcaption><strong>Haas Mosaic</strong></figcaption>
            </figure>
            <figure class="centered-image">
                <img src="./assets/south-mosaic.jpg" alt="Derek Hybrid Image">
                <figcaption><strong>South Hall Mosaic</strong></figcaption>
            </figure>
            <h2>Part B: Autostitching</h2>
            <h2>Corner Detection</h2>
            <p>
                For autostitching, we want to first create a set of interest points to use. 
                To create this initial set of interest points we can use the Harris Interest Point 
                Detector. We can use the Harris Interest Point Detector to get a matrix of "corner
                strengths" representing the strength of the interest points in the image and set of 
                interest points to use.
                <br>
                <br>
                Applying the detector below we get the following set of interest points for a sample
                image:
            </p>
            <div class="before-after-container">
                <figure class="image-container">
                    <img src="assets/haas-left-matplot.png" alt="Before Image" class="before-after-img">
                    <figcaption class="image-caption">
                        <strong>Haas - Left: Original</strong>
                    </figcaption>
                </figure>
                <figure class="image-container">
                    <img src="assets/haas-left-harris.png" alt="After Image" class="before-after-img">
                    <figcaption class="image-caption">
                        <strong>Haas - Left: Harris</strong>
                    </figcaption>
                </figure>
            </div>
            <h2>Adaptive Non-Maximal Suppression (ANMS)</h2>
            <p>
                We see that the Harris interest points are clustered together and not evenly spaced
                throughout the image. We can run adaptive non-maximal suppression to select interest points
                with strong corner reponse that are spaced through the image. For each interest point we compute
                the radius as follows:
                $$
                r_i = \min_j |\mathbf{x}_i - \mathbf{x}_j|, \text{ s.t. } f(\mathbf{x}_i) < c_{\text{robust}}f(\mathbf{x}_j), \mathbf{x}_j \in \mathcal{I}
                $$

                We select the top k points with the largest radii to make up our set of evenly spread out interest points.
            </p>
            <p>
                Setting k=500, here is the comparison of the Harris interest points and the points after running ANMS:
            </p>
            <div class="before-after-container">
                <figure class="image-container">
                    <img src="assets/haas-left-harris.png" alt="Before Image" class="before-after-img">
                    <figcaption class="image-caption">
                        <strong>Haas - Left: Harris</strong>
                    </figcaption>
                </figure>
                <figure class="image-container">
                    <img src="assets/haas-left-anms.png" alt="After Image" class="before-after-img">
                    <figcaption class="image-caption">
                        <strong>Haas - Left: ANMS</strong>
                    </figcaption>
                </figure>
            </div>
            <h2>Extracting Feature Descriptors</h2>
            <p>
                Once we have our finalized interest points, we want to extract features for each point. To do this we take a 40 x 40 window around 
                each point. We then downsample using a scaling factor of 5 to create 8 x 8 patches. We bias/gain-normalize to have zero mean and unit
                variance. We then flatten the patch into a vector, giving us a feature descriptor for each interest point.
            </p>
            <p>
                Below we have an example of normalized patch before it is flattened:
            </p>
            <figure class="centered-image">
                <img src="./assets/feature-descriptor.png" alt="Derek Hybrid Image">
                <figcaption class="image-caption">
                    <strong>Feature Descriptor Patch</strong>
                </figcaption>
            </figure>
            <h2>Feature Matching</h2>
            <p>
                With the features extracted, we need to match features across our images to form correspondences. We first compute the distances between
                the two sets of feature descriptors we have for our two images. Then we iterate through our first set of descriptors and find the first and
                second nearest neighbor in the second set of descriptors. To reduce the number of outliers we use Lowe's trick and compute ratio of the first nearest neighbor distannce
                and the second nearest neighbor distance. If the ratio is below some threshold, \(t\), we then count the feature in first feature descriptor set as a match with its
                nearest neighbor in the second feature descriptor set.
            </p>
            <p>Here are the feature matches for the School of Law using \(t = 0.1\):</p>
            <figure class="centered-image">
                <img src="./assets/feature-matching.png" alt="Derek Hybrid Image">
                <figcaption class="image-caption">
                    <strong>School of Law: Feature Matches</strong>
                </figcaption>
            </figure>
            <h2>RANSAC</h2>
            <p>
                Even with Lowe's trick we are left with some incorrect feature matches. When we compute the homography using least squares
                with these outliers we skew the compute homography, creating invalid stitching and warps.

                In order to remove the amount of outliers we apply RANSAC to create a set of inliers to compute our homography.
                <br>
                <br>
                The steps are as follows:
            </p>
            <ol class="steps-inline">
                <li>Select 4 feature matches at random</li>
                <li>Compute the homography H (exact)</li>
                <li>Compute inliers where \(dist(p_i', Hp_i) < \epsilon \)</li>
                <li>Repeat steps 1-3 until we hit our max iterations</li>
                <li>Keep the largest set of inliers found in our iterations</li>
                <li>Recompute the homography H using least-squares on the largest set of inliers</li>
            </ol>
            <p>
                Here are our feature matches after running RANSAC on the School of Law images:
            </p>
            <figure class="centered-image">
                <img src="./assets/inliers.png" alt="Derek Hybrid Image">
                <figcaption class="image-caption">
                    <strong>School of Law: RANSAC</strong>
                </figcaption>
            </figure>
            <h2>Results</h2>
            <p>Here are the results comparing the hand-stitched mosaics versus the auto-stitched mosaics using feature matching and RANSAC: </p>
            <div class="before-after-container">
                <figure class="image-container">
                    <img src="assets/law-mosaic.jpg" alt="Before Image" class="before-after-img">
                    <figcaption class="image-caption">
                        <strong>School of Law: Manual</strong>
                    </figcaption>
                </figure>
                <figure class="image-container">
                    <img src="assets/law-auto.jpg" alt="After Image" class="before-after-img">
                    <figcaption class="image-caption">
                        <strong>School of Law: Auto</strong>
                    </figcaption>
                </figure>
            </div>
            <div class="before-after-container">
                <figure class="image-container">
                    <img src="assets/haas-mosaic.jpg" alt="Before Image" class="before-after-img">
                    <figcaption class="image-caption">
                        <strong>Haas: Manual</strong>
                    </figcaption>
                </figure>
                <figure class="image-container">
                    <img src="assets/haas-auto.jpg" alt="After Image" class="before-after-img">
                    <figcaption class="image-caption">
                        <strong>Haas: Auto</strong>
                    </figcaption>
                </figure>
            </div>
            <div class="before-after-container">
                <figure class="image-container">
                    <img src="assets/south-mosaic.jpg" alt="Before Image" class="before-after-img">
                    <figcaption class="image-caption">
                        <strong>South Hall: Manual</strong>
                    </figcaption>
                </figure>
                <figure class="image-container">
                    <img src="assets/south-auto.jpg" alt="After Image" class="before-after-img">
                    <figcaption class="image-caption">
                        <strong>South Hall: Auto</strong>
                    </figcaption>
                </figure>
            </div>
            <h2>What I Learned</h2>
            <p>
                What I found particularly interesting and cool was Lowe's trick and RANSAC as a tool to mitigate incorrect correspondences
                and automatically chose the right ones to compute the homography.
            </p>
            <br>
            <br>
        </div>
    </section>
    <script src="script.js"></script>
</body>
</html>